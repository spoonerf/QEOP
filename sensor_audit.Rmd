---
title: "QEOP Sensor Audit"
author: "Fiona Spooner"
date: "`r Sys.Date()`"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                     warning=FALSE, message=FALSE)
```

Libraries required:

```{r}
library(ggplot2)
library(dplyr)
library(here)
library(reader)
library(knitr)
library(anytime)
```

Reading in the data from the CE Tools Server:

```{r}

dump<-read.table("qeop_dump_all.csv", fill=T, sep=",")

##adding in a column to identify each row with a sensor

dump$sensor<-NA
for (i in 1:15){
  start_id<-min(which(grepl( paste("qeop_batstore_",i, sep=""),dump[,1])))
  end_id<-max(which(grepl( paste("qeop_batstore_",i, sep=""),dump[,1])))
  dump[start_id:end_id,]$sensor<-paste("Sensor_",i,sep="")
  #print(i)
}

table(dump$sensor)


```

Removing redundant rows and the classification data as it is not relevant here:

```{r}
dump<-dump[,c(1,2,4,ncol(dump))]
dump<-dump[grepl("\t",dump[,1]),]
dump[,1]<-as.numeric(gsub("[\t(]","",dump[,1]))
dump[,3]<-as.numeric(gsub("[^0-9.]", "",  dump[,3]))

dump$sensor_no<-as.numeric(gsub("[^0-9.]", "",  dump$sensor))

colnames(dump)<-c("ID", "datetime", "prob_bat", "sensor", "sensor_no")

dump$datetime<-as.POSIXct(dump$datetime,format="%Y-%m-%d %H:%M:%S")

dump$date<- as.Date(dump$datetime)

dump$time<- format(dump$datetime, "%H:%M:%S")

```


Calculating the number of detections per day for each sensor:

```{r}
library(dplyr)

days_active<-dump %>%
  dplyr::select(date, sensor_no)%>%
  group_by(date,sensor_no)%>%
  mutate(count = n())%>%
  distinct()%>%
  ungroup()

days_active$sensor_no<-as.factor(days_active$sensor_no)
days_active$server<-"CE Tools"


```

Most of the daily data are saved in individual folders, data between 24th October 2017 and 9th May 2018 are grouped together into 6 folders. This code creates new folders for each date between 24th Oct and 9th May

```{r}
lf<-list.files(paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more", sep=""))

#subsetting folders with more than 10 chars
lf_gr<-lf[nchar(lf)>10]

#create dirs for all the missing dates - need to check which days are missing within this
fol_ds<-as.Date(unlist(strsplit(lf_gr, "_")))
mdays<-seq(min(fol_ds), max(fol_ds),by="days")

```

```{r, message=FALSE, eval=FALSE}
dir_maker<-function(mday){
  
  if (!dir.exists(paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/",mday, sep=""))){
    dir.create(path = paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/",mday, sep=""))
  }
    }
lapply(mdays, dir_maker)

```  

This code breaks up the .csv files by date and sensor, saves a file for each sensor within each date folder

```{r, eval=FALSE}


fold_split<-function(fol_name){
  
  fp<-paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/", fol_name, sep="" )
  fpl<-list.files(fp)
  lapply(fpl, file_split, fp = fp)
}

#here the anytime and anydate functions convert unix date formats to regular calendar dates and times

file_split<-function(file_name, fp){
  
  sensor_no<-as.numeric(gsub("[^0-9.]", "",  file_name))
  spl_csv<-read.csv(paste(fp,"/",file_name, sep=""))
  spl_csv$datetime<-anytime(spl_csv$timestamp/1000)#have to divide by 1000 as the numbers are stored to capture milliseconds
  spl_csv$date<-anydate(spl_csv$timestamp/1000)#have to divide by 1000 as the numbers are stored to capture milliseconds
  sp_df<-split(spl_csv, spl_csv$date)
  lapply(names(sp_df),function(x){write.csv(sp_df[[x]],file = paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/", sp_df[[x]]$date[1],"/","bat",sensor_no, ".csv", sep="" ),row.names = FALSE)})
  
}

lapply(lf_gr, fold_split)




```

Reading in the OpenSensors data, counting the number of rows in each file. Each row is a detection: 


```{r}

lf<-lf[nchar(lf) <=10]

sensor_count<-function(file, dir_id){
  
  sensor_no<-as.numeric(gsub("[^0-9.]", "",  file))
  count<-file.nrow(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id,"/", file,sep="")) #gives warning
  #count<-length(readr::count_fields(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id,"/", file,sep=""), tokenizer = readr::tokenizer_csv()))

  #remove file header if the file is a csv
  if (grepl("*csv", file)){
    count<-count - 1
  }

  out<-data.frame(dir_id,sensor_no, count)
  return(out)
  }

dir_count<-function(dir_id){
  files<-list.files(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id, sep=""))
  dir_out<-lapply(files, sensor_count, dir_id = dir_id)
  do.call("rbind", dir_out)
}

opensensors<-lapply(lf, dir_count)

open_df<-do.call("rbind", opensensors)
colnames(open_df)[1]<-"date"

open_df$server<-"Opensensors"

open_df$date<-as.Date(open_df$date)
open_df$sensor_no<-as.numeric(open_df$sensor_no)

```

Combining data from CE Tools and OpenSensors:

```{r}

all_sensors<-rbind(open_df, days_active)

min_date<-min(all_sensors$date)
max_date<-max(all_sensors$date)

all_dates<-seq(min_date, max_date, by="day")
all_df<-data.frame(rep(all_dates,15),rep(1:15, each = length(all_dates))) 
colnames(all_df)<-c("date", "sensor_no")

all_sensors_merge<-merge(all_df, all_sensors, all=T)
all_sensors_merge$sensor_no<-as.numeric(all_sensors_merge$sensor_no)

```


Additional information about the sensors from the documentation

```{r}

sensor_info<-read.csv("sensor_info.csv")

all_sensors_merge<-merge(all_sensors_merge, sensor_info)

```

Sensor 4 moved on 14th May 2018 so renaming data at this point onwards as 4_2

```{r}

all_sensors_merge<-all_sensors_merge %>%
 # filter(sensor_no == 4 & date >= as.Date("2018-05-14"))
  mutate(sensor_no=replace(sensor_no, sensor_no == 4 & date >= as.Date("2018-05-14"), 4.5))

all_sensors_merge %>%
  filter(server == "Opensensors")%>%
  summarize(max_date = max(date))

#last date opensensors was working

all_sensors_merge<-all_sensors_merge %>%
  mutate(server = replace(server, date <= as.Date("2018-06-18"), "Opensensors" ), server = replace(server, date > as.Date("2018-06-18"), "CETools"))


#save(all_sensors_merge, file = "all_sensor_data_2017-07-12_2019-2019_01_14")
```

```{r}

load("all_sensor_data_2017-07-12_2019-2019_01_14")

```

Plot of each sensor from `r min_date` to `r max_date`, the height of each row relates to the number of detections in each day:

```{r}
ggplot(all_sensors_merge, aes(x = date, y = sensor_no, group = sensor_no))+
  geom_line(color = "steelblue",aes(size = log10(count)))+
  scale_y_reverse(breaks = seq(1, 16, by = 1))+
  scale_x_date(date_breaks = "1 month", date_labels = "%m-%Y")+
  theme_bw()+
  #theme(panel.background = element_blank())+
  theme(axis.text.y = element_text(lineheight = 0.5 , size = 18),
        axis.text.x = element_text(size = 14, angle = 45, hjust = 1),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.text=element_text(size=18),
        legend.title=element_text(size=20))+
  labs(x = "Date", y = "Sensor No.", linetype = "test")+
  guides(colour = "none", size = guide_legend(title ="Detections\n(Log)"))

```



```{r, eval = FALSE, echo = FALSE}
ggplot(all_sensors_merge, aes(x = date, y = sensor_no, group = sensor_no))+
  geom_line(aes(size = count, col= server))+
  scale_y_reverse(breaks = seq(1, 16, by = 1))+
  scale_x_date(date_breaks = "1 month", date_labels = "%m-%Y")+
  theme_bw()+
  theme(axis.text.y = element_text(lineheight = 0.5 , size = 18),
        axis.text.x = element_text(size = 14, angle = 45, hjust = 1),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.text=element_text(size=18),
        legend.title=element_text(size=20))+
  labs(x = "Date", y = "Sensor No.", linetype = "test")+
  guides(colour = "none", size = guide_legend(title ="Detections\n(Log)"))

```




Tabular summary of the same data:

```{r}
kable(
  all_sensors_merge %>%
  group_by(sensor_no, server) %>%
  filter(!is.na(count))%>%
  summarise(first_date = min(date), last_date = max(date)))

```


Making plots like [Newson et al. 2015](https://www.sciencedirect.com/science/article/pii/S0006320715002323#f0010) 

Need to access time data from the Opensensors dataset

```{r}

ce_dirs<-list.dirs(here("data_archive/opensensors_Daniyar/qeoplogs_more/"))

#getting rid of the folders with multiple dates in 
ce_dirs<-ce_dirs[nchar(ce_dirs)==71]

df<-data.frame()

ce_tool_out<-function(ce_dir){
  file_list<-list.files(ce_dir)
  
  for (file in file_list){
         
      if(grepl(".csv", file)){
         df_temp = read.table(paste(ce_dir,"/", file, sep=""), sep=",", header = T, stringsAsFactors = F)
         df_temp$sensor_id<-as.numeric(gsub("\\D", "", file))
         df_temp$timestamp<-as.numeric(as.character(df_temp$timestamp))
         df_temp$timestamp<-anytime(df_temp$timestamp/1000)
         df_temp<-df_temp[,c("sensor_id","timestamp", "call_time", "prob_bat")]
      } 
    
      if (grepl(".txt", file)) {
         df_temp = read.table(paste(ce_dir,"/", file, sep=""), sep=",", fill= TRUE)
         df_temp$sensor_id<-as.numeric(gsub("\\D", "", file))
         df_temp$timestamp<-as.POSIXct(gsub("[^0-9.]", "", paste(df_temp$V3, df_temp$V4, ... =   df_temp$V5,df_temp$V6,df_temp$V7,df_temp$V8, sep=".")), format = ".%Y.%m.%d.%H.%M.%S")
         df_temp$call_time<-as.numeric(gsub("[^0-9.]", "", df_temp$V17))
         df_temp$prob_bat<-as.numeric(gsub("[^0-9.]", "", df_temp$V18))
         df_temp<-df_temp[,c("sensor_id","timestamp", "call_time", "prob_bat")]
        }
         
         df = rbind(df, df_temp)
         print(paste(ce_dir, file, sep="/"))
        
          }
  
  return(df)
}

all_df<-lapply(ce_dirs, ce_tool_out)

all_sens_df<-do.call("rbind", all_df)


all_sens_df$date<-as.Date(all_sens_df$timestamp)

all_sens_df$time<-format(all_sens_df$timestamp, "%H:%M:%S")

#write.csv(all_sens_df, "all_sensors_all_records.csv", row.names = FALSE)

```


Adding a month column
```{r}
library(chron)
library(scales)
library(lubridate)
library(ggplot2)

all_sens_df<-read.csv("all_sensors_all_records.csv")

all_sens_df$month<-months.Date(as.Date(all_sens_df$date))

all_sens_df$month<-factor(all_sens_df$month, levels = month.name)

all_sens_df$timestamp<-as.POSIXct(all_sens_df$timestamp)
#all_sens_df$time<-chron(times = all_sens_df$time)

t <- strftime(all_sens_df$timestamp, format="%H:%M:%S")

all_sens_df$time<-as.POSIXct(t, format="%H:%M:%S")

all_sens_df<-all_sens_df[complete.cases(all_sens_df),]

all_sens_df$minute_from_noon<-all_sens_df$time


midnight<-as.POSIXct("2019-02-14 00:00:00", format="%Y-%m-%d %H:%M:%S")

all_sens_df$midnight_diff<-difftime(all_sens_df$time, midnight, units = "secs")


ggplot(all_sens_df, aes(x = month, y = midnight_diff))+
  geom_boxplot()+ 
 # scale_y_datetime(limits = lims, trans = "reverse")
# scale_y_continuous(trans = "reverse")



#lims <- as.POSIXct(strptime(c("2019-02-14 23:00", "2019-02-14 01:00"), 
#                   format = "%Y-%m-%d %H:%M"))



#ggplot(month_mean_count, aes(x = month, y = )


```


```{r}
c_trans <- function(a, b, breaks = b$breaks, format = b$format) {
  a <- as.trans(a)
  b <- as.trans(b)

  name <- paste(a$name, b$name, sep = "-")

  trans <- function(x) a$trans(b$trans(x))
  inv <- function(x) b$inverse(a$inverse(x))

  trans_new(name, trans, inverse = inv, breaks = breaks, format=format)

}

rev_date <- c_trans("reverse", "time")

ggplot(all_sens_df, aes(x = month, y = time)) +
  geom_boxplot() + 
  scale_y_continuous(trans = rev_date, limits = lims)


```
