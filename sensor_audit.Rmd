---
title: "QEOP Sensor Audit"
author: "Fiona Spooner"
date: "`r Sys.Date()`"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                     warning=FALSE, message=FALSE)
```

Libraries required:

```{r}
library(ggplot2)
library(dplyr)
library(here)
library(reader)
library(knitr)
library(anytime)
```

Reading in the data from the CE Tools Server:

```{r}

dump<-read.table("qeop_dump_all.csv", fill=T, sep=",")

##adding in a column to identify each row with a sensor

dump$sensor<-NA
for (i in 1:15){
  start_id<-min(which(grepl( paste("qeop_batstore_",i, sep=""),dump[,1])))
  end_id<-max(which(grepl( paste("qeop_batstore_",i, sep=""),dump[,1])))
  dump[start_id:end_id,]$sensor<-paste("Sensor_",i,sep="")
  #print(i)
}

table(dump$sensor)


```

Removing redundant rows and the classification data as it is not relevant here:

```{r}
dump<-dump[,c(1,2,4,ncol(dump))]
dump<-dump[grepl("\t",dump[,1]),]
dump[,1]<-as.numeric(gsub("[\t(]","",dump[,1]))
dump[,3]<-as.numeric(gsub("[^0-9.]", "",  dump[,3]))

dump$sensor_no<-as.numeric(gsub("[^0-9.]", "",  dump$sensor))

colnames(dump)<-c("ID", "datetime", "prob_bat", "sensor", "sensor_no")

dump$datetime<-as.POSIXct(dump$datetime,format="%Y-%m-%d %H:%M:%S")

dump$date<- as.Date(dump$datetime)

dump$time<- format(dump$datetime, "%H:%M:%S")

```


Calculating the number of detections per day for each sensor:

```{r}
library(dplyr)

days_active<-dump %>%
  dplyr::select(date, sensor_no)%>%
  group_by(date,sensor_no)%>%
  mutate(count = n())%>%
  distinct()%>%
  ungroup()

days_active$sensor_no<-as.factor(days_active$sensor_no)
days_active$server<-"CE Tools"


```

Most of the daily data are saved in individual folders, data between 24th October 2017 and 9th May 2018 are grouped together into 6 folders. This code creates new folders for each date between 24th Oct and 9th May

```{r}
lf<-list.files(paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more", sep=""))

#subsetting folders with more than 10 chars
lf_gr<-lf[nchar(lf)>10]

#create dirs for all the missing dates - need to check which days are missing within this
fol_ds<-as.Date(unlist(strsplit(lf_gr, "_")))
mdays<-seq(min(fol_ds), max(fol_ds),by="days")

```

```{r, message=FALSE, eval=FALSE}
dir_maker<-function(mday){
  
  if (!dir.exists(paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/",mday, sep=""))){
    dir.create(path = paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/",mday, sep=""))
  }
    }
lapply(mdays, dir_maker)

```  

This code breaks up the .csv files by date and sensor, saves a file for each sensor within each date folder

```{r, eval=FALSE}


fold_split<-function(fol_name){
  
  fp<-paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/", fol_name, sep="" )
  fpl<-list.files(fp)
  lapply(fpl, file_split, fp = fp)
}

#here the anytime and anydate functions convert unix date formats to regular calendar dates and times

file_split<-function(file_name, fp){
  
  sensor_no<-as.numeric(gsub("[^0-9.]", "",  file_name))
  spl_csv<-read.csv(paste(fp,"/",file_name, sep=""))
  spl_csv$datetime<-anytime(spl_csv$timestamp/1000)#have to divide by 1000 as the numbers are stored to capture milliseconds
  spl_csv$date<-anydate(spl_csv$timestamp/1000)#have to divide by 1000 as the numbers are stored to capture milliseconds
  sp_df<-split(spl_csv, spl_csv$date)
  lapply(names(sp_df),function(x){write.csv(sp_df[[x]],file = paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/", sp_df[[x]]$date[1],"/","bat",sensor_no, ".csv", sep="" ),row.names = FALSE)})
  
}

lapply(lf_gr, fold_split)




```

Reading in the OpenSensors data, counting the number of rows in each file. Each row is a detection: 


```{r}

lf<-lf[nchar(lf) <=10]

sensor_count<-function(file, dir_id){
  
  sensor_no<-as.numeric(gsub("[^0-9.]", "",  file))
  count<-file.nrow(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id,"/", file,sep="")) #gives warning
  #count<-length(readr::count_fields(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id,"/", file,sep=""), tokenizer = readr::tokenizer_csv()))

  #remove file header if the file is a csv
  if (grepl("*csv", file)){
    count<-count - 1
  }

  out<-data.frame(dir_id,sensor_no, count)
  return(out)
  }

dir_count<-function(dir_id){
  files<-list.files(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id, sep=""))
  dir_out<-lapply(files, sensor_count, dir_id = dir_id)
  do.call("rbind", dir_out)
}

opensensors<-lapply(lf, dir_count)

open_df<-do.call("rbind", opensensors)
colnames(open_df)[1]<-"date"

open_df$server<-"Opensensors"

open_df$date<-as.Date(open_df$date)
open_df$sensor_no<-as.numeric(open_df$sensor_no)

```

Combining data from CE Tools and OpenSensors:

```{r}

all_sensors<-rbind(open_df, days_active)

min_date<-min(all_sensors$date)
max_date<-max(all_sensors$date)

all_dates<-seq(min_date, max_date, by="day")
all_df<-data.frame(rep(all_dates,15),rep(1:15, each = length(all_dates))) 
colnames(all_df)<-c("date", "sensor_no")

all_sensors_merge<-merge(all_df, all_sensors, all=T)
all_sensors_merge$sensor_no<-as.numeric(all_sensors_merge$sensor_no)

```


Additional information about the sensors from the documentation

```{r}

sensor_info<-read.csv("sensor_info.csv")

all_sensors_merge<-merge(all_sensors_merge, sensor_info)

```

Sensor 4 moved on 14th May 2018 so renaming data at this point onwards as 4_2

```{r}

all_sensors_merge<-all_sensors_merge %>%
 # filter(sensor_no == 4 & date >= as.Date("2018-05-14"))
  mutate(sensor_no=replace(sensor_no, sensor_no == 4 & date >= as.Date("2018-05-14"), 4.5))

all_sensors_merge %>%
  filter(server == "Opensensors")%>%
  summarize(max_date = max(date))

#last date opensensors was working

all_sensors_merge<-all_sensors_merge %>%
  mutate(server = replace(server, date <= as.Date("2018-06-18"), "Opensensors" ), server = replace(server, date > as.Date("2018-06-18"), "CETools"))


#save(all_sensors_merge, file = "all_sensor_data_2017-07-12_2019-2019_01_14")
```

```{r}

load("all_sensor_data_2017-07-12_2019-2019_01_14")

```

Plot of each sensor from `r min_date` to `r max_date`, the height of each row relates to the number of detections in each day:

```{r}
ggplot(all_sensors_merge, aes(x = date, y = sensor_no, group = sensor_no))+
  geom_line(color = "steelblue",aes(size = log10(count)))+
  scale_y_reverse(breaks = seq(1, 16, by = 1))+
  scale_x_date(date_breaks = "1 month", date_labels = "%m-%Y")+
  theme_bw()+
  #theme(panel.background = element_blank())+
  theme(axis.text.y = element_text(lineheight = 0.5 , size = 18),
        axis.text.x = element_text(size = 14, angle= 45, hjust = 1),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.text=element_text(size=18),
        legend.title=element_text(size=20))+
  labs(x = "Date", y = "Sensor No.", linetype = "test")+
  #scale_fill_continuous(breaks = c(0,1,2,3,4), labels = c("1","10", "100","1000","10000"), guide =guide_legend(title ="Detections\n(Log10)"))
  scale_size_continuous(breaks = c(0,1,2,3,4),labels = c("1","10","100", "1000", "10000"))+
  guides(size = guide_legend(title ="Detections"))

```



```{r, eval = FALSE, echo = FALSE}
ggplot(all_sensors_merge, aes(x = date, y = sensor_no, group = sensor_no))+
  geom_line(aes(size = count, col= server))+
  scale_y_reverse(breaks = seq(1, 16, by = 1))+
  scale_x_date(date_breaks = "1 month", date_labels = "%m-%Y")+
  theme_bw()+
  theme(axis.text.y = element_text(lineheight = 0.5 , size = 18),
        axis.text.x = element_text(size = 14, angle = 45, hjust = 1),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.text=element_text(size=18),
        legend.title=element_text(size=20))+
  labs(x = "Date", y = "Sensor No.", linetype = "test")+
  guides(colour = "none", size = guide_legend(title ="Detections\n(Log10)"))

```




Tabular summary of the same data:

```{r}
kable(
  all_sensors_merge %>%
  group_by(sensor_no, server) %>%
  filter(!is.na(count))%>%
  summarise(first_date = min(date), last_date = max(date)))

```


Making plots like [Newson et al. 2015](https://www.sciencedirect.com/science/article/pii/S0006320715002323#f0010) 

Need to access time data from the Opensensors dataset

```{r, eval= FALSE}

ce_dirs<-list.dirs(here("data_archive/opensensors_Daniyar/qeoplogs_more/"))

#getting rid of the folders with multiple dates in 
ce_dirs<-ce_dirs[nchar(ce_dirs)==71]

df<-data.frame()

ce_tool_out<-function(ce_dir){
  file_list<-list.files(ce_dir)
  
  for (file in file_list){
         
      if(grepl(".csv", file)){
         df_temp = read.table(paste(ce_dir,"/", file, sep=""), sep=",", header = T, stringsAsFactors = F)
         df_temp$sensor_id<-as.numeric(gsub("\\D", "", file))
         df_temp$timestamp<-as.numeric(as.character(df_temp$timestamp))
         df_temp$timestamp<-anytime(df_temp$timestamp/1000)
         df_temp<-df_temp[,c("sensor_id","timestamp", "call_time", "prob_bat")]
      } 
    
      if (grepl(".txt", file)) {
         df_temp = read.table(paste(ce_dir,"/", file, sep=""), sep=",", fill= TRUE)
         df_temp$sensor_id<-as.numeric(gsub("\\D", "", file))
         df_temp$timestamp<-as.POSIXct(gsub("[^0-9.]", "", paste(df_temp$V3, df_temp$V4,df_temp$V5,df_temp$V6,df_temp$V7,df_temp$V8, sep=".")), format = ".%Y.%m.%d.%H.%M.%S")
         df_temp$call_time<-as.numeric(gsub("[^0-9.]", "", df_temp$V17))
         df_temp$prob_bat<-as.numeric(gsub("[^0-9.]", "", df_temp$V18))
         df_temp<-df_temp[,c("sensor_id","timestamp", "call_time", "prob_bat")]
        }
         
         df = rbind(df, df_temp)
         #print(paste(ce_dir, file, sep="/"))
        
          }
  
  return(df)
}

all_df<-lapply(ce_dirs, ce_tool_out)

all_sens_df<-do.call("rbind", all_df)


all_sens_df$date<-as.Date(all_sens_df$timestamp)

all_sens_df$time<-format(all_sens_df$timestamp, "%H:%M:%S")

#write.csv(all_sens_df, "all_sensors_all_records.csv", row.names = FALSE)

```


Adding a month column and formatting data for plotting record data over the year
```{r}
library(chron)
library(scales)
library(lubridate)
library(ggplot2)

all_sens_df<-read.csv("all_sensors_all_records.csv")

sensor_info<-read.csv("sensor_info.csv")

all_sens_info<-merge(all_sens_df, sensor_info, by.x = "sensor_id", by.y = "Sensor_no")

all_sens_info$month<-months.Date(as.Date(all_sens_info$date))

all_sens_info$month<-factor(all_sens_info$month, levels = month.name)

all_sens_info$timestamp<-as.POSIXct(all_sens_info$timestamp)

t <- strftime(all_sens_info$timestamp, format="%H:%M:%S")

all_sens_info$time<-as.POSIXct(t, format="%H:%M:%S")

all_sens_info<-all_sens_info[complete.cases(all_sens_info),]

########trying it out with all data 

all_sens_info$Habitat<-as.character(all_sens_info$Habitat)

#shifting anything before 6pm forwrd by a day
all_sens_info[hour(all_sens_info$timestamp) < 18, ]$time<-all_sens_info[hour(all_sens_info$timestamp) < 18, ]$time +days(1)

all_sens_info_night<-all_sens_info[all_sens_info$time < as.POSIXct(paste(Sys.Date()+1, " 06:00:00 GMT", sep="")),]

ggplot(all_sens_info_night, aes(x = month, y = time))+
  geom_boxplot(aes(fill=Habitat))+
  facet_wrap(.~sensor_id)+
  labs(x = "Month", y = "Time")+
  scale_x_discrete(labels=month.abb[c(1,4,7,10)], breaks = c("January", "April", "July", "October")) +
  theme_bw()

```


```{r}
library(suncalc)

QEOP_loc<-c(mean(unique(all_sens_info$Lat)), mean(unique(all_sens_info$Lon)))

suntimes<-getSunlightTimes(lat = QEOP_loc[1], lon = QEOP_loc[2], date = as.Date(unique(all_sens_info$date)), keep = c("sunrise", "sunset"))

suntimes$date<-as.Date(suntimes$date)
all_sens_info_night$date<-as.Date(all_sens_info_night$date)

df<-merge(suntimes, all_sens_info_night, by="date")
df$sunrise <- strftime(df$sunrise, format="%H:%M:%S")
df$sunrise <- as.POSIXct(df$sunrise, format="%H:%M:%S")

ggplot(df, aes(x = month, y = time))+
  geom_boxplot(aes(fill=Habitat))+ 
  geom_line(aes(x = date, y = sunrise))


ggplot(df, aes(x = date, y = sunrise))+
  #geom_boxplot(aes(fill=Habitat))+ 
  geom_line()




```

Narrative for each sensor:

Bat sensor one

```{r}
library(leaflet)
library(htmltools)
library(mapview)

bat = makeIcon("bat.png", 36, 36)

s1<-dplyr::filter(all_sens_info, sensor_id == 1)

file_1<-'D:/Fiona/QEOP/data_archive/sensor_pics/sensor_1.png'
file_2<-'D:/Fiona/QEOP/data_archive/sensor_pics/sensor_2.png'

content_1 <- paste(sep = "<br/>",
               paste0("<b>Sensor 1: </b>"),
               paste0("<b>Lamp post ID: </b>", "CP03"),
               paste0("<b>Direction: </b>", "Towards grass"),
               paste0("<b>Habitat: </b>", "Parkland"),
               paste0("<b>Lighting: </b>", "Not directly onto grass, but directed into trees on path."),
               paste0("<b>Light levels (Lux): : </b>", "On path 0.08; on grass 0.01."))

content_2 <- paste(sep = "<br/>",
               paste0("<b>Sensor 2: </b>"),
               paste0("<b>Lamp post ID: </b>", "TC472"),
               paste0("<b>Direction: </b>", "Facing towards the river"),
               paste0("<b>Habitat: </b>", "Water"))

m <- leaflet() %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  #addMarkers(lng=s1$Lon[1], lat=s1$Lat[1], popup="Sensor 1: <br> Lamp post ID: CP03 <br> Direction: towards grass <br> Habitat: Parkland <br> Lighting: Not directly onto grass, but directed into trees on path. <br> Light levels (Lux): on path 0.08. On grass 0.01.", icon = bat)
  addMarkers(lng=s1$Lon[1], lat=s1$Lat[1], popup=popupImage(file), icon = bat, label =  htmltools::HTML(content), labelOptions = labelOptions(direction = "bottom") )

m

```



