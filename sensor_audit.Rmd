---
title: "QEOP Sensor Audit"
author: "Fiona Spooner"
date: "`r Sys.Date()`"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                     warning=FALSE, message=FALSE)
```

Libraries required:

```{r}
library(ggplot2)
library(dplyr)
library(here)
library(reader)
library(knitr)
library(anytime)
```

Reading in the data from the CE Tools Server:

```{r}

dump<-read.table("qeop_dump_all.csv", fill=T, sep=",")

##adding in a column to identify each row with a sensor

dump$sensor<-NA
for (i in 1:15){
  start_id<-min(which(grepl( paste("qeop_batstore_",i, sep=""),dump[,1])))
  end_id<-max(which(grepl( paste("qeop_batstore_",i, sep=""),dump[,1])))
  dump[start_id:end_id,]$sensor<-paste("Sensor_",i,sep="")
  #print(i)
}

table(dump$sensor)


```

Removing redundant rows and the classification data as it is not relevant here:

```{r}
dump<-dump[,c(1,2,4,ncol(dump))]
dump<-dump[grepl("\t",dump[,1]),]
dump[,1]<-as.numeric(gsub("[\t(]","",dump[,1]))
dump[,3]<-as.numeric(gsub("[^0-9.]", "",  dump[,3]))

dump$sensor_no<-as.numeric(gsub("[^0-9.]", "",  dump$sensor))

colnames(dump)<-c("ID", "datetime", "prob_bat", "sensor", "sensor_no")

dump$datetime<-as.POSIXct(dump$datetime,format="%Y-%m-%d %H:%M:%S")

dump$date<- as.Date(dump$datetime)

dump$time<- format(dump$datetime, "%H:%M:%S")

```


Calculating the number of detections per day for each sensor:

```{r}

days_active<-dump %>%
  select(date, sensor_no)%>%
  group_by(date,sensor_no)%>%
  mutate(count = n())%>%
  distinct()%>%
  ungroup()

days_active$sensor_no<-as.factor(days_active$sensor_no)
days_active$server<-"CE Tools"


```

Most of the daily data are saved in individual folders, data between 24th October 2017 and 9th May 2018 are grouped together into 6 folders. This code creates new folders for each date between 24th Oct and 9th May

```{r}
lf<-list.files(paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more", sep=""))

#subsetting folders with more than 10 chars
lf_gr<-lf[nchar(lf)>10]

#create dirs for all the missing dates - need to check which days are missing within this
fol_ds<-as.Date(unlist(strsplit(lf_gr, "_")))
mdays<-seq(min(fol_ds), max(fol_ds),by="days")

```

```{r, message=FALSE, eval=FALSE}
dir_maker<-function(mday){
  
  if (!dir.exists(paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/",mday, sep=""))){
    dir.create(path = paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/",mday, sep=""))
  }
    }
lapply(mdays, dir_maker)

```  

This code breaks up the .csv files by date and sensor, saves a file for each sensor within each date folder

```{r, eval=FALSE}


fold_split<-function(fol_name){
  
  fp<-paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/", fol_name, sep="" )
  fpl<-list.files(fp)
  lapply(fpl, file_split, fp = fp)
}

file_split<-function(file_name, fp){
  
  sensor_no<-as.numeric(gsub("[^0-9.]", "",  file_name))
  spl_csv<-read.csv(paste(fp,"/",file_name, sep=""))
  spl_csv$datetime<-anytime(spl_csv$timestamp/1000)#have to divide by 1000 as the numbers are stored to capture milliseconds
  spl_csv$date<-anydate(spl_csv$timestamp/1000)#have to divide by 1000 as the numbers are stored to capture milliseconds
  sp_df<-split(spl_csv, spl_csv$date)
  lapply(names(sp_df),function(x){write.csv(sp_df[[x]],file = paste(here(),"/data_archive/opensensors_Daniyar/qeoplogs_more/", sp_df[[x]]$date[1],"/","bat",sensor_no, ".csv", sep="" ),row.names = FALSE)})
  
}

lapply(lf_gr, fold_split)




```

Reading in the OpenSensors data, counting the number of rows in each file. Each row is a detection: 


```{r}



sensor_count<-function(file, dir_id){
  
  sensor_no<-as.numeric(gsub("[^0-9.]", "",  file))
  count<-file.nrow(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id,"/", file,sep="")) #gives warning
  #count<-length(readr::count_fields(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id,"/", file,sep=""), tokenizer = readr::tokenizer_csv()))

  #remove file header if the file is a csv
  if (grepl("*csv", file)){
    count<-count - 1
  }

  out<-data.frame(dir_id,sensor_no, count)
  return(out)
  }

dir_count<-function(dir_id){
  files<-list.files(paste(here(), "/data_archive/opensensors_Daniyar/qeoplogs_more/", dir_id, sep=""))
  dir_out<-lapply(files, sensor_count, dir_id = dir_id)
  do.call("rbind", dir_out)
}

opensensors<-lapply(lf, dir_count)

open_df<-do.call("rbind", opensensors)
colnames(open_df)[1]<-"date"

open_df$server<-"Opensensors"

open_df$date<-as.Date(open_df$date)
open_df$sensor_no<-as.numeric(open_df$sensor_no)

```

Combining data from CE Tools and OpenSensors:

```{r}

all_sensors<-rbind(open_df, days_active)

min_date<-min(all_sensors$date)
max_date<-max(all_sensors$date)

all_dates<-seq(min_date, max_date, by="day")
all_df<-data.frame(rep(all_dates,15),rep(1:15, each = length(all_dates))) 
colnames(all_df)<-c("date", "sensor_no")

all_sensors_merge<-merge(all_df, all_sensors, all=T)
all_sensors_merge$sensor_no<-as.numeric(all_sensors_merge$sensor_no)

```

Plot of each sensor from `r min_date` to `r max_date`, the height of each row relates to the number of detections in each day:

```{r}
ggplot(all_sensors_merge, aes(x = date, y = sensor_no, group = sensor_no, col="blue"))+
  geom_line(aes(size = log10(count), col= "blue"))+
  scale_y_reverse(breaks = seq(1, 16, by = 1))+
  scale_x_date(date_breaks = "1 month", date_labels = "%m-%Y")+
  theme_bw()+
  theme(axis.text.y = element_text(lineheight = 0.5 , size = 18),
        axis.text.x = element_text(size = 14, angle = 45, hjust = 1),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.text=element_text(size=18),
        legend.title=element_text(size=20))+
  labs(x = "Date", y = "Sensor No.", linetype = "test")+
  guides(colour = "none", size = guide_legend(title ="Detections\n(Log)"))

```



```{r, eval = FALSE, echo = FALSE}
library(devtools)
install_github("bbc/bbplot")
library(bbplot)

ggplot(all_sensors_merge, aes(x = date, y = sensor_no, group = sensor_no))+
  geom_line(aes(size = count, col= server))+
  scale_y_reverse(breaks = seq(1, 16, by = 1))+
  scale_x_date(date_breaks = "1 month", date_labels = "%m-%Y")+
#  theme(axis.text.y = element_text(lineheight = 0.5 , size = 18),
        # axis.text.x = element_text(size = 14, angle = 45, hjust = 1),
        # axis.title.x = element_text(size = 20),
        # axis.title.y = element_text(size = 20),
        # legend.text=element_text(size=18),
        # legend.title=element_text(size=20))+
  labs(x = "Date", y = "Sensor No.", linetype = "test")+
  guides(colour = "none", size = guide_legend(title ="Detections\n(Log)"))+
  bbc_style()


```




Tabular summary of the same data:

```{r}
kable(
  all_sensors_merge %>%
  group_by(sensor_no, server) %>%
  filter(!is.na(count))%>%
  summarise(first_date = min(date), last_date = max(date)))

```